{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GgZB-qLDc8wD"
      },
      "source": [
        "# Forecasting the Sales of a Furniture store\n",
        "We are using Superstore sales data for furniture sales between 2014 to 2017 and apply a simple model to forecast for 2018"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r69dcSa2c8wH"
      },
      "source": [
        "## Content\n",
        "\n",
        "1. **[Import packages](#import_packages)**\n",
        "2. **[Load data](#load_data)**\n",
        "3. **[Data preparation](#data_preparation)**\n",
        "    - 3.1 - [Dimensions of Dataset](#data_dimension)\n",
        "    - 3.2 - [Statistical Summary](#Stat_sum)\n",
        "    - 3.3 - [Checking Data Type and Missing Values](#check_data_type)\n",
        "    - 3.4 - [Indexing with Date](#Indexing_with_Date)\n",
        "4. **[Time Series Analysis](#Time_Series_Analysis)**\n",
        "    - 4.1 - [Visualizing data](#Visualizing_data)\n",
        "    - 4.2 - [Sampling](#Sampling)\n",
        "    - 4.3 - [Checking Stationarity](#Checking_Stationarity)\n",
        "    - 4.4 - [Decomposing](#Decomposing)\n",
        "5. **[Time Series Forcasting using ARIMA](#Time_Series_Forcasting_using_ARIMA)**\n",
        "    - 5.1 - [Parameter Selection](#Parameter_Selection)\n",
        "    - 5.2 - [Fitting the ARIMA model](#Fitting_the_ARIMA)\n",
        "    - 5.3 - [Validating Forecasts](#Validating_Forecasts)\n",
        "    - 5.4 - [Calculating MSE and RMSE](#Calculating_MSE_and_RMSE)\n",
        "    - 5.5 - [Visualizing the Forecast](#Visualizing_the_Forecast)\n",
        "6. **[Conclusion](#Conclusion)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPVZonTqc8wI"
      },
      "source": [
        "<a id='import_packages'></a>\n",
        "# 1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "caIrvwM-c8wJ"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGgdJ1tc8wM"
      },
      "source": [
        "<a id='load_data'></a>\n",
        "# 2. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W_uAECUc8wM"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>Load the data using read_csv() function from pandas<br>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "rPOJ3k4kc8wN",
        "outputId": "c0cb3b26-98d8-41b5-aa97-fd20c02069cb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-30b285a22f92>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfurniture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Super_Store.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp1252'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfurniture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Super_Store.csv'"
          ]
        }
      ],
      "source": [
        "furniture = pd.read_csv(\"Super_Store.csv\",sep=\",\", encoding='cp1252')\n",
        "furniture.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-QnQgUIc8wP"
      },
      "source": [
        "<a id='data_preparation'></a>\n",
        "# 3. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cwI1xvcc8wQ"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>The process of data preparation entails cleansing, structuring and integrating data to make it ready for analysis. <br><br>\n",
        "                        Here we will analyze and prepare data to perform regression techniques:<br>\n",
        "                        1. Check dimensions and data types of the dataframe <br>\n",
        "                        2. Study summary statistics<br>\n",
        "                        3. Converting date into standard format<br>\n",
        "                        4. Check for missing values<br>\n",
        "                        5. Study correlation<br>\n",
        "                                       </b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSaoDGN0c8wR"
      },
      "source": [
        "<a id='data_dimension'></a>\n",
        "# 3.1 Dimensions of Dataset\n",
        "We get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lRSm3juc8wR"
      },
      "outputs": [],
      "source": [
        "# Checking structure of the data\n",
        "furniture.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di9KzKFEc8wS"
      },
      "source": [
        "<a id='Stat_sum'></a>\n",
        "# 3.2 Statistical Summary\n",
        "Here we take a look at the summary of each attribute.\n",
        "\n",
        "This includes the count, mean, the min and max values as well as percentiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ggh-OYcc8wS"
      },
      "outputs": [],
      "source": [
        "furniture.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjxPpFf2c8wT"
      },
      "source": [
        "<a id='check_data_type'></a>\n",
        "## 3.3 Checking for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEnpCysNc8wT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# summary of the data\n",
        "furniture.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1mRuqJjc8wU"
      },
      "source": [
        "Checking the stock time stamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1-aulTUc8wU"
      },
      "outputs": [],
      "source": [
        "furniture['Order Date'].min(), furniture['Order Date'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK0uCa_Pc8wV"
      },
      "source": [
        "We remove the columns that we do not need as well as check missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FgwreTHnc8wV"
      },
      "outputs": [],
      "source": [
        "cols = ['Row ID', 'Order ID', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Quantity', 'Discount', 'Profit']\n",
        "furniture.drop(cols, axis=1, inplace=True)\n",
        "furniture = furniture.sort_values('Order Date')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O7EWT8Oc8wV"
      },
      "source": [
        "Checking for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AelLyVlec8wW"
      },
      "outputs": [],
      "source": [
        "furniture.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svo7svhWc8wW"
      },
      "source": [
        "<table align='left'>\n",
        "    <tr>\n",
        "        <td width='8%'>\n",
        "            <img src='note.png'>\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align='left', style='font-size:120%'>\n",
        "                    <b>There are no missing values<br>\n",
        "                    </br></b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Bhy7Zrc8wX"
      },
      "source": [
        "<a id='Indexing_with_Date'></a>\n",
        "## 3.5 Indexing with Date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdDJjI9Gc8wX"
      },
      "source": [
        "Aggregate price by date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LusFNgTyc8wX"
      },
      "outputs": [],
      "source": [
        "furniture = furniture.groupby('Order Date')['Sales'].sum().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTcctko_c8wX"
      },
      "outputs": [],
      "source": [
        "furniture['Order Date'] = pd.to_datetime(furniture['Order Date'])\n",
        "furniture.set_index('Order Date', inplace=True)\n",
        "furniture.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLmEgoUcc8wY"
      },
      "outputs": [],
      "source": [
        "furniture.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WCskPj_c8wY"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "<b>Resampling the datetime data. Here we use the start of each month as the timestamp and take the average daily sales value for a particular month since working with the current datetime data becomes tricky</b>     </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0sRyl_Sc8wY"
      },
      "source": [
        "<a id='Time_Series_Analysis'></a>\n",
        "# 4. Time Series Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMYEoT2Xc8wZ"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b> Now we analysis Time series data to do so we need to perform following steps <br><br>\n",
        "                        1. Visualizing Data <br>\n",
        "                        2. Sampling<br>\n",
        "                        3. Checking Stationarity <br>\n",
        "                        4. Decomposing<br>\n",
        "                      </b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJXS54REc8wZ"
      },
      "source": [
        "<a id='Visualizing_data'></a>\n",
        "## 4.1 Visualizing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGfTlUEcc8wZ"
      },
      "outputs": [],
      "source": [
        "furniture.plot(figsize=(15, 6))\n",
        "plt.show()\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3QNgVsCc8wa"
      },
      "source": [
        "<a id='Sampling'></a>\n",
        "## 4.2 Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p8j1purTc8wa"
      },
      "outputs": [],
      "source": [
        "y = furniture['Sales'].resample('MS').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhQ02FYSc8wa"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCnEHtKqc8wb"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "decomposition = seasonal_decompose(y)\n",
        "\n",
        "plt.plot(y, label = 'Original')\n",
        "plt.legend(loc = 'best')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=30)\n",
        "\n",
        "trend = decomposition.trend\n",
        "plt.show()\n",
        "plt.plot(trend, label = 'Trend')\n",
        "plt.legend(loc = 'best')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=30)\n",
        "\n",
        "seasonal = decomposition.seasonal\n",
        "plt.show()\n",
        "plt.plot(seasonal, label = 'Seasonal')\n",
        "plt.legend(loc = 'best')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=30)\n",
        "\n",
        "residual = decomposition.resid\n",
        "plt.show()\n",
        "plt.plot(residual, label = 'Residual')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQOC1JCc8wb"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>The plot clearly indicates that the time series has seasonality pattern.The sales are always low at the beginning of the year and high at the end of the year. There is always an upward trend within any single year with a couple of low months in the mid of the year</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fy2LhjTc8wb"
      },
      "source": [
        "<a id='Checking_Stationarity'></a>\n",
        "## 4.3 Checking Stationarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vih1ZbL_c8wb"
      },
      "source": [
        "Our first step in time-series analysis should be to check whether there is any evidence of a trend or seasonal effects and, if there is, remove them. Augmented Dickey-Fuller(ADF) statistics is one of the more widely used statistical test to check whether your time series is stationary or non-stationary. It uses an autoregressive model and optimizes an information criterion across multiple different lag values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emimr7S6c8wc"
      },
      "source": [
        "**Null Hypothesis: The series has a unit root (value of a =1)(not stationary)**\n",
        "\n",
        "**Alternate Hypothesis: The series has no unit root (stationary)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mBOsht4fc8wc"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxxzdDP8c8wc"
      },
      "outputs": [],
      "source": [
        "from pandas import Series\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "result = adfuller(y)\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxKQjqdMc8wc"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>We can see that our statistic value of -4.756843 is less than the value of -3.578 at 1%. This suggests that we can reject the null hypothesis with a significance level of less than 1% (i.e. a low probability that the result is a statistical fluke). Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.\n",
        "\n",
        "The p-value is 0.000009, which is way below the threshold (0.05). Hence the null-hypothesis is rejected. It suggests the time series does not have a unit root, meaning it is stationary.</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm4b4viEc8we"
      },
      "source": [
        "<a id='Time_Series_Forcasting_using_ARIMA'></a>\n",
        "# 5. Time Series Forcasting using ARIMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB_8uKwAc8we"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b> We will use ARIMA for forecasting our time series. ARIMA is also denoted as ARIMA(p,d,q) where p,d,q accounts for seasonality, trend and noise in the time series data</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECrn5ojpc8we"
      },
      "outputs": [],
      "source": [
        "p = d = q = range(0, 2)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL0L__sjc8we"
      },
      "source": [
        "<a id='Parameter_Selection'></a>\n",
        "## 5.1 Parameter Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxDiJLBNc8we"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>We use “grid search” to find the optimal set of parameters that yields the best performance for our model</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJiqOgPKc8wf"
      },
      "outputs": [],
      "source": [
        "from pylab import rcParams\n",
        "for param in pdq:\n",
        "    for param_seasonal in seasonal_pdq:\n",
        "        try:\n",
        "            mod = sm.tsa.statespace.SARIMAX(y, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
        "            results = mod.fit()\n",
        "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRGjPDFnc8wf"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>We are selecting those parameter which has minimum AIC score</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHt5TDVoc8wf"
      },
      "source": [
        "<a id='Fitting_the_ARIMA'></a>\n",
        "## 5.2 Fitting the ARIMA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IROP59NDc8wg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "mod = sm.tsa.statespace.SARIMAX(y,order=(1, 1, 1),seasonal_order=(1, 1, 0, 12),enforce_stationarity=False,enforce_invertibility=False)\n",
        "results = mod.fit()\n",
        "print(results.summary().tables[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL-O1XkAc8wg"
      },
      "source": [
        "**Running model diagnostiscs to check any unusual behaviour**\n",
        "<br>1. If the model is correctly specified and the parameter estimates are reasonably close to the true values, then the residuals should have nearly the properties of white noise.\n",
        "\n",
        "<br>2. Plots can be used to better understand the distribution of errors beyond summary statistics. We would expect the forecast errors to be normally distributed around a zero mean.\n",
        "\n",
        "<br>3. The Q-Q plot can be used to quickly check the normality of the distribution of residual errors.\n",
        "\n",
        "<br>4. Finally, visualizing the autocorrelation for the residual errors. The x-axis shows the lag and the y-axis shows the correlation between an observation and the lag variable, where correlation values are between -1 and 1 for negative and positive correlations respectively. We would not expect there to be any correlation between the residuals. This would be shown by autocorrelation scores being below the threshold of significance (dashed and dotted horizontal lines on the plot)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bY6-1Ctc8wh"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>The model diagnostics indicates that the model residuals are near normally distributed</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwIz6WxZc8wh"
      },
      "source": [
        "<a id='Validating_Forecasts'></a>\n",
        "## 5.3 Validating Forecasts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56VOMyfIc8wh"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"key.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>We compare predicted sales to real sales of the time series to understand the accuracy of our forecasts</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVUEjWU1c8wh"
      },
      "outputs": [],
      "source": [
        "#set forecasts to start at 2017–01–01 to the end of the data to forecast\n",
        "pred = results.get_prediction(start=pd.to_datetime('2017-01-01'), dynamic=False)\n",
        "pred_ci = pred.conf_int()\n",
        "ax = y['2014':].plot(label='observed')\n",
        "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n",
        "ax.fill_between(pred_ci.index,\n",
        "                pred_ci.iloc[:, 0],\n",
        "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Furniture Sales')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoRUlr5Ec8wj"
      },
      "source": [
        "The above plot indicates the observed value and the rolling forecast predications (A rolling forecast is an add/drop process for predicting the future over a set period of time). The predicated values align well with the true values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0waPEHfc8wj"
      },
      "source": [
        "<a id=\"Calculating_MSE_and_RMSE\"> </a>\n",
        "## 5.4 Calculating MSE and RMSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swZoarc3c8wj"
      },
      "outputs": [],
      "source": [
        "y_forecasted = pred.predicted_mean\n",
        "y_truth = y['2017-01-01':]\n",
        "mse = ((y_forecasted - y_truth) ** 2).mean()\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
        "print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ276RKZpKa-"
      },
      "outputs": [],
      "source": [
        "mae=(abs(y_forecasted-y_truth)).mean()\n",
        "print('The Mean Absolute Error of our forecasts is {}'.format(round(mae), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TruSfWbc8wk"
      },
      "source": [
        "<table align=\"left\">\n",
        "    <tr>\n",
        "        <td width=\"8%\">\n",
        "            <img src=\"note.png\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <div align=\"left\", style=\"font-size:120%\">\n",
        "                    <b>MSE measures the average of the squares of the errors of an estimator i.e. the average squared difference between the estimated values and what is estimated. RMSE tells us that our model was able to forecast the average daily furniture sales in the test set within 160.34 of the real sales..</b>\n",
        "                </font>\n",
        "            </div>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cMzYOLWc8wk"
      },
      "source": [
        "<a id=\"Visualizing_the_Forecast\"> </a>\n",
        "## 5.5 Visualizing the Forecast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNG3WHhic8wk"
      },
      "outputs": [],
      "source": [
        "pred_uc = results.get_forecast(steps=13)\n",
        "pred_ci = pred_uc.conf_int()\n",
        "ax = y.plot(label='observed', figsize=(14, 7))\n",
        "pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
        "ax.fill_between(pred_ci.index,\n",
        "                pred_ci.iloc[:, 0],\n",
        "                pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Furniture Sales')\n",
        "print(pred_ci)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w1Sb4xsc8wk"
      },
      "source": [
        "<a id=\"Conclusion\"> </a>\n",
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7acl_j3c8wl"
      },
      "source": [
        "We observe that sales of furniture produces seasonal pattern. Early of the year is the off season for furniture sales in the superstore. The sales for furniture increases linearly over time."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}